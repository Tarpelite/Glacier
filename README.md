# Glacier 函数式深度学习编程语言

`陈天宇 BY2006105`
`闫坤 BY2006175`


## 语言设计的背景及范型

### 背景与动机

随着深度学习在越来越多的领域展现出惊人的效果，来自不同背景的研究者都渴望构建自己的深度学习模型来解决领域的前沿问题。Google和Facebook等互联网巨头很早就注意到了这个问题，推出了tensorflow和pytorch等框架，在工业领域和研究领域都取得了巨大的成功。但是，和自然数学语言相近的深度学习编程工具却一直没有出现，大多数深度学习框架遵循了传统增量开发的思想，为了兼容主流的编程语言，在设计之初便包含了大量过程式、命令式和面向对象的特性，导致了一些难以避免的缺陷。

pytorch和tensorflow提供了两个主要的功能：具有强大的GPU加速的张量计算和包含自动求导系统的深度神经网络。

随着pytorch和tensorflow的进一步推广，这些缺陷也在逐渐放大。首先，对于神经网络的抽象，无论是pytorch还是tensorflow，都将神经网络层描述为对象，而面向对象的继承、多态和封装特性却很容易造成计算图构建的困扰。其次，中间层隐变量在过程式语言环境下无可避免地需要被储存，造成了内存管理的麻烦。更重要的是，python脚本语言的特性限制了其类型检查的功能，而程序员在开发深度学习的过程中不得不将大量精力用于保证矩阵大小的配合，而矩阵大小不匹配的错误，只有在运行时才会由硬件驱动抛出异常，会造成较大的运维风险。最后，缺少编译环节的脚本语言无法有效估计底层加速卡的资源占用情况，因而容易造成资源的浪费，在云计算和集群训练的时代会大大降低生产效率。

因此我们设计了Glacier(冰川)函数式编程语言，针对深度学习模型的日常开发和研究人员，目的是从函数式的视角重新描述深度学习的模型构建过程，解决上述框架的历史遗留问题，并通过TVM的Relay语言作为中间代码，最终编译成可被TVM加载的ONNX模型。

### 语言特性

考虑到纯函数式语言的特性，没有赋值语句和可修改变量会增大自动求导的难度。本语言的语法主要参考了函数式语言Haskell和过程式语言Python，并根据我们的需求对其语法进行截取。例如选取了Haskell的函数签名和类型系统。在人工智能的视野下，“川”是涌动的水流，是大数据时代的流式数据，也是模型训练中来回流动的梯度信息，“冰川”是大数据的凝练，是被学习固化的深度模型结构，也是模型中被永久保存的固定参数。为了提供基本的模型构建能力，Glacier语言提供的主要特性有：







## 语言的语法、语义规格说明

### Glacier 语法

#### 关键字

#### EBNF 语法

### Glacier 类型推导

### Glacier 内存优化

